{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import asarray\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is used correctly\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories\n",
    "test_dir = os.path.join(\"D:/\", \"# Studie/# MSc Data Science/Applied Machine Learning/Kaggle_Project\", \"test_set\")\n",
    "train_dir = os.path.join(\"D:/\", \"# Studie/# MSc Data Science/Applied Machine Learning/Kaggle_Project\", \"train_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. This part shows the code of our first approach, our self-build CNN.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the model\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image loader\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                           zoom_range=0.1,\n",
    "                                           rotation_range=30,\n",
    "                                           width_shift_range=0.2,\n",
    "                                           height_shift_range=0.2,\n",
    "                                           horizontal_flip=True,\n",
    "                                           shear_range=0.1,\n",
    "                                           fill_mode='nearest',\n",
    "                                           validation_split=0.2) # Generator for our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation datasets\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='categorical',\n",
    "                                                           subset='training')\n",
    "\n",
    "val_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='categorical',\n",
    "                                                           subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, labels = next(train_data_gen)\n",
    "\n",
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# plot 5 training images\n",
    "plotImages(sample_training_images[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with the labels versus the indices\n",
    "class_label_dict = train_data_gen.class_indices\n",
    "\n",
    "# print three sample images to check if the indices are correctly tied to the labels\n",
    "for i in range(0,3):\n",
    "    image = sample_training_images[i]\n",
    "    label = labels[i]\n",
    "    plt.imshow(image)\n",
    "    data = asarray(image)\n",
    "    print(data.shape)\n",
    "    prediction = np.argmax(label)\n",
    "    print(\"Given prediction\", prediction)\n",
    "    for key, value in class_label_dict.items():\n",
    "        if value == prediction:\n",
    "            print(\"Actual key\", key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    \n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "        \n",
    "    Dense(80, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this trains the model, we added learning rate reducer when the model hits a plateau\n",
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch= train_data_gen.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps= val_data_gen.samples // batch_size,\n",
    "    callbacks=[ReduceLROnPlateau(factor=.5, patience=4, verbose=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function plots the train accuracy and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(sample_training_images, labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=test_dir,\n",
    "                                                           shuffle=False,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for the test set\n",
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator)\n",
    "predictions= np.argmax(pred, axis=1)\n",
    "filenames = test_generator.filenames\n",
    "filenames1 = [i[9:] for i in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize the submission dataframe\n",
    "submission_df = pd.DataFrame( {'img_name': filenames1,'prediction': predictions, 'label': \" \"})\n",
    "\n",
    "# get labels from the predictions\n",
    "for index, row in submission_df.iterrows():\n",
    "    prediction = row['prediction']\n",
    "    for key, value in class_label_dict.items():\n",
    "        if prediction == value:\n",
    "            submission_df.at[index, 'label'] = key\n",
    "\n",
    "# export the submission_df to upload to kaggle\n",
    "submission_df = submission_df.drop(columns=\"prediction\")\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. This part of the code will be our Ensemble model\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the model\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "n_members = 20 #number of ensemble models to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes n_member number of CNNs with new data and saves every model to file\n",
    "\n",
    "class_label_dict = []   # global variable for class label indices dictionary\n",
    "\n",
    "for _ in range(n_members):\n",
    "    \n",
    "    # every iteration resample images from the train and validation set\n",
    "    val_data_gen.reset()\n",
    "    train_data_gen.reset()\n",
    "    \n",
    "    # save class indices for prediction\n",
    "    class_label_dict = train_data_gen.class_indices\n",
    "    \n",
    "    # define a model\n",
    "    model = Sequential([\n",
    "        Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "\n",
    "        Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "\n",
    "        Conv2D(128, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(512, activation='relu'),\n",
    "\n",
    "        Dense(80, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    # train the model\n",
    "    history = model.fit_generator(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch= train_data_gen.samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps= val_data_gen.samples // batch_size,\n",
    "        callbacks=[ReduceLROnPlateau(factor=.5, patience=4, verbose=1)]\n",
    "    )\n",
    "    # save the model to file for later\n",
    "    model.save('good_model'+ str(_)+ '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# craete dataframe for model predictions\n",
    "submission_df = pd.DataFrame( {'img_name': [i[9:] for i in test_generator.filenames]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes the predictions of a model, and transforms it into the correct label\n",
    "def get_label_value(prediction):\n",
    "    pred = np.argmax(prediction, axis=1)\n",
    "    labels = []\n",
    "    for i in pred:\n",
    "        for key, value in class_label_dict.items():\n",
    "            if i == value:\n",
    "                labels.append(key)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every model, predict the labels for all test images and append to the submission_df\n",
    "for i in range(n_members):\n",
    "    \n",
    "    test_generator.reset()\n",
    "    \n",
    "    filename = 'model_' + str(i) + '.h5'\n",
    "    current_model = tf.keras.models.load_model(filename)\n",
    "    \n",
    "    pred=current_model.predict_generator(test_generator)\n",
    "    print('model_'+str(i))\n",
    "    submission_df[filename] = get_label_value(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mode of all predictions\n",
    "submission_df['label'] = submission_df.filter(like='model').mode(axis=1).iloc[:, 0]\n",
    "\n",
    "# write file with submission\n",
    "submission_df[['img_name', 'label']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. This part of code will show how we used ResNet for our transfer learning model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the model\n",
    "batch_size = 16 # larger batch size did not fit the GPU unfortunately\n",
    "epochs = 20\n",
    "IMG_HEIGHT = 224 \n",
    "IMG_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how the images have to be pre-processed\n",
    "train_image_generator = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "                                           validation_split=0.2) # Generator for our training data\n",
    "\n",
    "# generator for our training data\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                       directory=train_dir,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                       class_mode='categorical',\n",
    "                                                       subset='training')\n",
    "\n",
    "# generator for our validation data\n",
    "val_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                       directory=train_dir,\n",
    "                                                       shuffle=True,\n",
    "                                                       target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                       class_mode='categorical',\n",
    "                                                       subset='validation')\n",
    "\n",
    "# save class indices for prediction\n",
    "class_label_dict = train_data_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our base model is the ResNet50 model\n",
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_HEIGHT, IMG_WIDTH ,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# global average pooling layer between the pre-trained network and the last dense layer\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "# dense layer that puts out the 80 classes\n",
    "prediction_layer = tf.keras.layers.Dense(80, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "# unfreezing the last 50 layers (we have tried with and without unfreezing)\n",
    "base_model.trainable=False\n",
    "for layer in base_model.layers[150:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch= train_data_gen.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps= val_data_gen.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test images\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=test_dir,\n",
    "                                                           shuffle=False,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode=\"categorical\")\n",
    "\n",
    "\n",
    "# create dataframe for model predictions\n",
    "submission_df = pd.DataFrame( {'img_name': [i[9:] for i in test_generator.filenames]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions and use get_label_value function to get proper labels\n",
    "pred=model.predict_generator(test_generator)\n",
    "submission_df['label'] = get_label_value(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write file with submission\n",
    "submission_df[['img_name', 'label']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
